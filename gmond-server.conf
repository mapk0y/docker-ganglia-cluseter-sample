globals {
  daemonize = no
  setuid = yes
  user = ganglia
  debug_level = 1
  mute = no
  deaf = no
  gexec = yes
  host_dmax = 0 /*secs */
  max_udp_msg_len = 1472
  cleanup_threshold = 300 /*secs */
  send_metadata_interval = 0
}

cluster {
  name = "Example"
}

udp_send_channel {
  mcast_join = 239.2.11.71
  port = 8649
  ttl = 1
}

udp_recv_channel {
  mcast_join = 239.2.11.71
  port = 8649
  bind = 239.2.11.71
}


modules {
  module {
    name = "core_metrics"
  }
  module {
    name = "cpu_module"
    path = "/usr/lib/ganglia/modcpu.so"
  }
}


collection_group {
  collect_once = yes
  time_threshold = 20
  metric {
    name = "heartbeat"
  }
}

/* This collection group will send general info about this host every 1200 secs.
   This information doesn't change between reboots and is only collected once. */
collection_group {
  collect_once = yes
  time_threshold = 1200
  metric {
    name = "cpu_num"
    title = "CPU Count"
  }
  metric {
    name = "cpu_speed"
    title = "CPU Speed"
  }
#  metric {
#    name = "mem_total"
#    title = "Memory Total"
#  }
#  /* Should this be here? Swap can be added/removed between reboots. */
#  metric {
#    name = "swap_total"
#    title = "Swap Space Total"
#  }
#  metric {
#    name = "boottime"
#    title = "Last Boot Time"
#  }
#  metric {
#    name = "machine_type"
#    title = "Machine Type"
#  }
#  metric {
#    name = "os_name"
#    title = "Operating System"
#  }
#  metric {
#    name = "os_release"
#    title = "Operating System Release"
#  }
  metric {
    name = "location"
    title = "Location"
  }
}

/* This collection group will send the status of gexecd for this host every 300 secs */
/* Unlike 2.5.x the default behavior is to report gexecd OFF.  */
collection_group {
  collect_once = yes
  time_threshold = 300
  metric {
    name = "gexec"
    title = "Gexec Status"
  }
}

/* This collection group will collect the CPU status info every 20 secs.
   The time threshold is set to 90 seconds.  In honesty, this time_threshold could be
   set significantly higher to reduce unneccessary network chatter. */
collection_group {
  collect_every = 20
  time_threshold = 90
  /* CPU status */
  metric {
    name = "cpu_user"
    value_threshold = "1.0"
    title = "CPU User"
  }
  metric {
    name = "cpu_system"
    value_threshold = "1.0"
    title = "CPU System"
  }
  metric {
    name = "cpu_idle"
    value_threshold = "5.0"
    title = "CPU Idle"
  }
  metric {
    name = "cpu_nice"
    value_threshold = "1.0"
    title = "CPU Nice"
  }
  metric {
    name = "cpu_aidle"
    value_threshold = "5.0"
    title = "CPU aidle"
  }
  metric {
    name = "cpu_wio"
    value_threshold = "1.0"
    title = "CPU wio"
  }
  /* The next two metrics are optional if you want more detail...
     ... since they are accounted for in cpu_system.
  metric {
    name = "cpu_intr"
    value_threshold = "1.0"
    title = "CPU intr"
  }
  metric {
    name = "cpu_sintr"
    value_threshold = "1.0"
    title = "CPU sintr"
  }
  */
}

#collection_group {
#  collect_every = 20
#  time_threshold = 90
#  /* Load Averages */
#  metric {
#    name = "load_one"
#    value_threshold = "1.0"
#    title = "One Minute Load Average"
#  }
#  metric {
#    name = "load_five"
#    value_threshold = "1.0"
#    title = "Five Minute Load Average"
#  }
#  metric {
#    name = "load_fifteen"
#    value_threshold = "1.0"
#    title = "Fifteen Minute Load Average"
#  }
#}

#/* This group collects the number of running and total processes */
#collection_group {
#  collect_every = 80
#  time_threshold = 950
#  metric {
#    name = "proc_run"
#    value_threshold = "1.0"
#    title = "Total Running Processes"
#  }
#  metric {
#    name = "proc_total"
#    value_threshold = "1.0"
#    title = "Total Processes"
#  }
#}
